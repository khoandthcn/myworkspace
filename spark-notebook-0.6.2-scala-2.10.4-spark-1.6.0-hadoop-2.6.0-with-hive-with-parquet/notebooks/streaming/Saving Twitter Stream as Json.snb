{
  "metadata" : {
    "name" : "Saving Twitter Stream as Json",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "#Twitter example"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Set up"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Set local repo for deps"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : ":local-repo /tmp/repo",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Add streaming + twitter deps + Gson (to convert back to Json)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : ":dp org.apache.spark % spark-streaming_2.10 % 1.4.0\norg.apache.spark % spark-streaming-twitter_2.10 % 1.4.0\ncom.google.code.gson % gson % 2.3\n- org.apache.spark % spark-core_2.10 % _\n- org.apache.hadoop % _ % _",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Install the twitter credentials "
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "**Note:** we are using the `env` variables here. For this, adapt the following and execute before launching the server\n```\n  export TWITTER_CONSUMER_KEY=...\n  export TWITTER_CONSUMER_SECRET=\"...\n  export TWITTER_ACCESS_TOKEN=...\n  export TWITTER_ACCESS_TOKEN_SECRET=...\n```"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "def $(s:String) = sys.env(s)\nSystem.setProperty(\"twitter4j.oauth.consumerKey\", $(\"TWITTER_CONSUMER_KEY\"))\nSystem.setProperty(\"twitter4j.oauth.consumerSecret\", $(\"TWITTER_CONSUMER_SECRET\"))\nSystem.setProperty(\"twitter4j.oauth.accessToken\", $(\"TWITTER_ACCESS_TOKEN\"))\nSystem.setProperty(\"twitter4j.oauth.accessTokenSecret\", $(\"TWITTER_ACCESS_TOKEN_SECRET\"))\n\"twitter settings done!\"",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Spark streaming"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Create context with batch of 10 minutes duration"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.streaming.{Minutes, StreamingContext}\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.streaming.twitter._\n\nval ssc = new StreamingContext(sparkContext, Minutes(10))",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Listen twitter stream "
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "#### We're going to **filter** the tweets to only those containing the following words."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val filters = Array(\"spark\", \"scala\", \"music\", \"machinelearning\", \"sparknotebook\", \"apachespark\", \"docker\",\n                    \"apachemesos\")",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "#### Create the twitter listeners"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val twitterStream = TwitterUtils.createStream(ssc, None, filters)",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Convert back to Json and save"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Set the number of files we want per batch"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val partitionsEachInterval = 10 // 10 files per time max",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "#### The following will convert each RDD, each Partition elements to Json (using Gson) and save it in a local (can be changed) directory."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "twitterStream\n  .foreachRDD((rdd, time) => {\n    val count = rdd.count()\n    if (count > 0) {\n      val outputRDD = rdd.repartition(partitionsEachInterval)\n      outputRDD.mapPartitions{ it =>\n        val gson = new com.google.gson.Gson()\n        it.map(gson.toJson(_))\n      }.saveAsTextFile(\"/tmp/twitter-stream-json/tweets_\" + time.milliseconds.toString)\n    }\n  })",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "###  Start listening twitter"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "This will listen the twitter stream, and the computation above will update the `resuilt` every `2s` using the last `60s` of values."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "ssc.start()",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Stop listening twitter "
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "// commented to all 'run all' :-D\nssc.stop(false)",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}